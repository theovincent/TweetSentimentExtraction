{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data base import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sample_data\n",
    "\n",
    "nb_samples = 10\n",
    "path_save = Path(\"../data/samples/sample_{}.csv\".format(nb_samples))\n",
    "path_csv = Path(\"../data/train.csv\")\n",
    "\n",
    "SMALL_DATA = sample_data.SampleData(\n",
    "    path_csv, nb_samples=nb_samples,\n",
    "    save=True, path_save=path_save\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           textID                                               text  \\\n",
      "10413  a4bb6136b2   Sorry but there is no parking space. And I ju...   \n",
      "15225  d63253be9a   WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEEP OUT MY ...   \n",
      "15331  3de9819b40  In the mood for shrimp scampi but I don`t have...   \n",
      "22638  add1c95bee          Star Trek.. Did not disappoint!  5 star!!   \n",
      "20551  87954b6e95  On my way home in the sunshine with a bag full...   \n",
      "22687  eaba181d46   prolly E71... I can`t think of anything else ...   \n",
      "15340  2c570c2fb3   that is a good pic  All the guys looked good ...   \n",
      "4524   7e9df3893e   Looks like you did the full Lincoln Marathon ...   \n",
      "12510  74d3120b7f   YAY YOU! So proud of you!  and I`m not even b...   \n",
      "1959   9f61b74d16  Something strange in the air lately. Been sett...   \n",
      "\n",
      "                                           selected_text  sentiment  \n",
      "10413                                              Sorry         -1  \n",
      "15225  WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEEP OUT MY N...          0  \n",
      "15331                             I don`t have vermouth.         -1  \n",
      "22638                      Did not disappoint!  5 star!!          1  \n",
      "20551  On my way home in the sunshine with a bag full...          0  \n",
      "22687                                      unfortunately         -1  \n",
      "15340                                               good          1  \n",
      "4524            That is awesome, the HM was tough for me          0  \n",
      "12510  YAY YOU! So proud of you!  and I`m not even be...          0  \n",
      "1959                                             good sm          1  \n"
     ]
    }
   ],
   "source": [
    "print(SMALL_DATA.sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_descriptor import vectorize_string, convert_labels, descriptor\n",
    "\n",
    "\n",
    "ALPHANUM_ONLY = False\n",
    "WORD_SIZE = 12\n",
    "SENTENCE_SIZE = 20\n",
    "FILL_WITH = \"$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_string_train = np.zeros((nb_samples, SENTENCE_SIZE), dtype=object)\n",
    "X_train = np.zeros((nb_samples, WORD_SIZE * SENTENCE_SIZE))\n",
    "Y_train = np.zeros((nb_samples, SENTENCE_SIZE))\n",
    "\n",
    "for i in range(len(SMALL_DATA.sample_data)):\n",
    "    X_string_train[i] = vectorize_string(\n",
    "        SMALL_DATA.sample_data[\"text\"].to_numpy()[i],\n",
    "        alphanumeric_only=ALPHANUM_ONLY,\n",
    "        sentence_size=SENTENCE_SIZE,\n",
    "        word_size=WORD_SIZE,\n",
    "        fill_with=FILL_WITH\n",
    "    )\n",
    "    X_train[i] = descriptor(X_string_train[i], alphanumeric_only=ALPHANUM_ONLY).reshape(-1)\n",
    "    \n",
    "    Y_train[i] = convert_labels(\n",
    "        X_string_train[i],\n",
    "        vectorize_string(\n",
    "            SMALL_DATA.sample_data[\"selected_text\"].to_numpy()[i],\n",
    "            alphanumeric_only=ALPHANUM_ONLY,\n",
    "            sentence_size=SENTENCE_SIZE,\n",
    "            word_size=WORD_SIZE,\n",
    "            fill_with=FILL_WITH\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi,$$$$$$$$$' 'the$$$$$$$$$' 'parody$$$$$$' 'for$$$$$$$$$'\n",
      " 'iPhone$$$$$$' 'is$$$$$$$$$$' 'hysterical,$' 'not$$$$$$$$$'\n",
      " 'because$$$$$' 'it`s$$$$$$$$' 'funny,$$$$$$' 'but$$$$$$$$$'\n",
      " 'because$$$$$' 'one$$$$$$$$$' 'cannot$$$$$$' 'play$$$$$$$$'\n",
      " 'the$$$$$$$$$' 'video$$$$$$$' 'on$$$$$$$$$$' 'iPhone$$$$$$']\n",
      "[104. 105.  44.  36.  36.  36.  36.  36.  36.  36.  36.  36. 116. 104.\n",
      " 101.  36.  36.  36.  36.  36.  36.  36.  36.  36. 112.  97. 114. 111.\n",
      " 100. 121.  36.  36.  36.  36.  36.  36. 102. 111. 114.  36.  36.  36.\n",
      "  36.  36.  36.  36.  36.  36. 105.  80. 104. 111. 110. 101.  36.  36.\n",
      "  36.  36.  36.  36. 105. 115.  36.  36.  36.  36.  36.  36.  36.  36.\n",
      "  36.  36. 104. 121. 115. 116. 101. 114. 105.  99.  97. 108.  44.  36.\n",
      " 110. 111. 116.  36.  36.  36.  36.  36.  36.  36.  36.  36.  98. 101.\n",
      "  99.  97. 117. 115. 101.  36.  36.  36.  36.  36. 105. 116.  96. 115.\n",
      "  36.  36.  36.  36.  36.  36.  36.  36. 102. 117. 110. 110. 121.  44.\n",
      "  36.  36.  36.  36.  36.  36.  98. 117. 116.  36.  36.  36.  36.  36.\n",
      "  36.  36.  36.  36.  98. 101.  99.  97. 117. 115. 101.  36.  36.  36.\n",
      "  36.  36. 111. 110. 101.  36.  36.  36.  36.  36.  36.  36.  36.  36.\n",
      "  99.  97. 110. 110. 111. 116.  36.  36.  36.  36.  36.  36. 112. 108.\n",
      "  97. 121.  36.  36.  36.  36.  36.  36.  36.  36. 116. 104. 101.  36.\n",
      "  36.  36.  36.  36.  36.  36.  36.  36. 118. 105. 100. 101. 111.  36.\n",
      "  36.  36.  36.  36.  36.  36. 111. 110.  36.  36.  36.  36.  36.  36.\n",
      "  36.  36.  36.  36. 105.  80. 104. 111. 110. 101.  36.  36.  36.  36.\n",
      "  36.  36.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X_string_train[0])\n",
    "print(X_train[0])\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import  KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                    weights='distance')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_neighbors = 2\n",
    "\n",
    "knn = KNeighborsRegressor(nb_neighbors, weights=\"distance\")\n",
    "knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.post_processing import pred_to_sentence, sentence_to_string, filter_character\n",
    "\n",
    "pred = knn.predict(X_train)\n",
    "meaning_sentences = pred_to_sentence(X_string_train, pred)\n",
    "\n",
    "results = []\n",
    "for sentence in meaning_sentences:\n",
    "    result = \"\"\n",
    "    for word in sentence:\n",
    "        filtered_word = filter_character(word, \"$\")\n",
    "        if len(filtered_word) != 0:\n",
    "            result += filtered_word + \" \"\n",
    "    results.append(result)\n",
    "results=np.array(results, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi, the parody for iPhone is hysterical, not because it`s funny, but because one cannot play the video on iPhone '\n",
      " 'with ' 'sad ' '_Yavanna me too. she`s everywhere.. ' 'Watching Matilda '\n",
      " 'it just might work. ' 'dont be ' 'Happy Mother`s Day '\n",
      " 'wish i was 17 again ' 'bloody ']\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi, the parody for iPhone is hysterical, not because it`s funny, but because one cannot play the video on iPhone'\n",
      " 'with' 'sad' '_Yavanna me too. she`s everywhere...' 'Watching Matilda'\n",
      " 'it just might work.' 'dont be gloomy.' 'Happy Mother`s Day'\n",
      " 'wish i was 17 again' 'bloody']\n"
     ]
    }
   ],
   "source": [
    "print(SMALL_DATA.sample_data[\"selected_text\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333332\n"
     ]
    }
   ],
   "source": [
    "from utils.loss import jaccard\n",
    "\n",
    "avg = 0\n",
    "for i in range(len(results)):\n",
    "    avg += jaccard(results[i], SMALL_DATA.sample_data[\"selected_text\"].to_numpy()[i])\n",
    "avg /= len(results)\n",
    "\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
