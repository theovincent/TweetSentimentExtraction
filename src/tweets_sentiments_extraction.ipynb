{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data base import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sample_data\n",
    "\n",
    "nb_samples = 10\n",
    "path_save = Path(\"../data/samples/sample_{}.csv\".format(nb_samples))\n",
    "path_csv = Path(\"../data/train.csv\")\n",
    "\n",
    "SMALL_DATA = sample_data.SampleData(\n",
    "    path_csv, nb_samples=nb_samples,\n",
    "    save=True, path_save=path_save\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           textID                                               text  \\\n",
      "17705  8ef0a6c70f   hi, the parody for iPhone is hysterical, not ...   \n",
      "3675   f18b9435c8                                              with    \n",
      "3718   9de58e1b43  : Am sad i got no money on my phone. Ahh well ...   \n",
      "11104  7496134179               _Yavanna me too. she`s everywhere...   \n",
      "11420  950c79ea38                                   Watching Matilda   \n",
      "24401  cd470720c9           have your own style. it just might work.   \n",
      "11699  7b033330b9   dont be gloomy...go out and get urself ice-cr...   \n",
      "26901  e822e3ead5        Happy Mother`s Day to every mommy out there   \n",
      "20624  4c60d96a1a                                wish i was 17 again   \n",
      "1054   4f5340eafa  _nexus he has to have a new suitcase, but he i...   \n",
      "\n",
      "                                           selected_text  sentiment  \n",
      "17705  hi, the parody for iPhone is hysterical, not b...          0  \n",
      "3675                                                with          0  \n",
      "3718                                                 sad         -1  \n",
      "11104               _Yavanna me too. she`s everywhere...          0  \n",
      "11420                                   Watching Matilda          0  \n",
      "24401                                it just might work.          1  \n",
      "11699                                    dont be gloomy.          1  \n",
      "26901                                 Happy Mother`s Day         -1  \n",
      "20624                                wish i was 17 again          1  \n",
      "1054                                              bloody         -1  \n"
     ]
    }
   ],
   "source": [
    "print(SMALL_DATA.sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_descriptor import vectorize_string, convert_labels, descriptor\n",
    "\n",
    "\n",
    "ALPHANUM_ONLY = False\n",
    "WORD_SIZE = 12\n",
    "SENTENCE_SIZE = 20\n",
    "FILL_WITH = \"$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_string_train = np.zeros((nb_samples, SENTENCE_SIZE), dtype=object)\n",
    "X_train = np.zeros((nb_samples, WORD_SIZE * SENTENCE_SIZE))\n",
    "Y_train = np.zeros((nb_samples, SENTENCE_SIZE))\n",
    "\n",
    "for i in range(len(SMALL_DATA.sample_data)):\n",
    "    X_string_train[i] = vectorize_string(\n",
    "        SMALL_DATA.sample_data[\"text\"].to_numpy()[i],\n",
    "        alphanumeric_only=ALPHANUM_ONLY,\n",
    "        sentence_size=SENTENCE_SIZE,\n",
    "        word_size=WORD_SIZE,\n",
    "        fill_with=FILL_WITH\n",
    "    )\n",
    "    X_train[i] = descriptor(X_string_train[i], alphanumeric_only=ALPHANUM_ONLY).reshape(-1)\n",
    "    \n",
    "    Y_train[i] = convert_labels(\n",
    "        X_string_train[i],\n",
    "        vectorize_string(\n",
    "            SMALL_DATA.sample_data[\"selected_text\"].to_numpy()[i],\n",
    "            alphanumeric_only=ALPHANUM_ONLY,\n",
    "            sentence_size=SENTENCE_SIZE,\n",
    "            word_size=WORD_SIZE,\n",
    "            fill_with=FILL_WITH\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi,$$$$$$$$$' 'the$$$$$$$$$' 'parody$$$$$$' 'for$$$$$$$$$'\n",
      " 'iPhone$$$$$$' 'is$$$$$$$$$$' 'hysterical,$' 'not$$$$$$$$$'\n",
      " 'because$$$$$' 'it`s$$$$$$$$' 'funny,$$$$$$' 'but$$$$$$$$$'\n",
      " 'because$$$$$' 'one$$$$$$$$$' 'cannot$$$$$$' 'play$$$$$$$$'\n",
      " 'the$$$$$$$$$' 'video$$$$$$$' 'on$$$$$$$$$$' 'iPhone$$$$$$']\n",
      "[104. 105.  44.  36.  36.  36.  36.  36.  36.  36.  36.  36. 116. 104.\n",
      " 101.  36.  36.  36.  36.  36.  36.  36.  36.  36. 112.  97. 114. 111.\n",
      " 100. 121.  36.  36.  36.  36.  36.  36. 102. 111. 114.  36.  36.  36.\n",
      "  36.  36.  36.  36.  36.  36. 105.  80. 104. 111. 110. 101.  36.  36.\n",
      "  36.  36.  36.  36. 105. 115.  36.  36.  36.  36.  36.  36.  36.  36.\n",
      "  36.  36. 104. 121. 115. 116. 101. 114. 105.  99.  97. 108.  44.  36.\n",
      " 110. 111. 116.  36.  36.  36.  36.  36.  36.  36.  36.  36.  98. 101.\n",
      "  99.  97. 117. 115. 101.  36.  36.  36.  36.  36. 105. 116.  96. 115.\n",
      "  36.  36.  36.  36.  36.  36.  36.  36. 102. 117. 110. 110. 121.  44.\n",
      "  36.  36.  36.  36.  36.  36.  98. 117. 116.  36.  36.  36.  36.  36.\n",
      "  36.  36.  36.  36.  98. 101.  99.  97. 117. 115. 101.  36.  36.  36.\n",
      "  36.  36. 111. 110. 101.  36.  36.  36.  36.  36.  36.  36.  36.  36.\n",
      "  99.  97. 110. 110. 111. 116.  36.  36.  36.  36.  36.  36. 112. 108.\n",
      "  97. 121.  36.  36.  36.  36.  36.  36.  36.  36. 116. 104. 101.  36.\n",
      "  36.  36.  36.  36.  36.  36.  36.  36. 118. 105. 100. 101. 111.  36.\n",
      "  36.  36.  36.  36.  36.  36. 111. 110.  36.  36.  36.  36.  36.  36.\n",
      "  36.  36.  36.  36. 105.  80. 104. 111. 110. 101.  36.  36.  36.  36.\n",
      "  36.  36.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X_string_train[0])\n",
    "print(X_train[0])\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import  KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                    weights='distance')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_neighbors = 2\n",
    "\n",
    "knn = KNeighborsRegressor(nb_neighbors, weights=\"distance\")\n",
    "knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.post_processing import pred_to_sentence, sentence_to_string, filter_character\n",
    "\n",
    "pred = knn.predict(X_train)\n",
    "meaning_sentences = pred_to_sentence(X_string_train, pred)\n",
    "\n",
    "results = []\n",
    "for sentence in meaning_sentences:\n",
    "    result = \"\"\n",
    "    for word in sentence:\n",
    "        filtered_word = filter_character(word, \"$\")\n",
    "        if len(filtered_word) != 0:\n",
    "            result += filtered_word + \" \"\n",
    "    results.append(result)\n",
    "results=np.array(results, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi, the parody for iPhone is hysterical, not because it`s funny, but because one cannot play the video on iPhone '\n",
      " 'with ' 'sad ' '_Yavanna me too. she`s everywhere.. ' 'Watching Matilda '\n",
      " 'it just might work. ' 'dont be ' 'Happy Mother`s Day '\n",
      " 'wish i was 17 again ' 'bloody ']\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi, the parody for iPhone is hysterical, not because it`s funny, but because one cannot play the video on iPhone'\n",
      " 'with' 'sad' '_Yavanna me too. she`s everywhere...' 'Watching Matilda'\n",
      " 'it just might work.' 'dont be gloomy.' 'Happy Mother`s Day'\n",
      " 'wish i was 17 again' 'bloody']\n"
     ]
    }
   ],
   "source": [
    "print(SMALL_DATA.sample_data[\"selected_text\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333332\n"
     ]
    }
   ],
   "source": [
    "from utils.loss import jaccard\n",
    "\n",
    "avg = 0\n",
    "for i in range(len(results)):\n",
    "    avg += jaccard(results[i], SMALL_DATA.sample_data[\"selected_text\"].to_numpy()[i])\n",
    "avg /= len(results)\n",
    "\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
