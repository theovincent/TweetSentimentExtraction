{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data base import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sample_data\n",
    "\n",
    "# -- Get the data -- #\n",
    "NB_SAMPLES = 1000\n",
    "TRAIN_SAMPLE = Path(\"../data/samples/sample_{}_train.csv\".format(NB_SAMPLES))\n",
    "VALID_SAMPLE = Path(\"../data/samples/sample_{}_validation.csv\".format(NB_SAMPLES))\n",
    "TRAIN_SAMPLE = pd.read_csv(TRAIN_SAMPLE).to_numpy()\n",
    "VALID_SAMPLE = pd.read_csv(VALID_SAMPLE).to_numpy()\n",
    "\n",
    "\n",
    "# -- Clean the data -- #\n",
    "from utils.clean_data import clean_data\n",
    "TRAIN_SAMPLE = clean_data(TRAIN_SAMPLE)\n",
    "VALID_SAMPLE = clean_data(VALID_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TRAIN_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "#### TWEET_ORIGINALS : List of the tweets : Array, shape = (len(nb_tweets))\n",
    "#### TWEET_STRINGS : List of the list of the word of each tweet : List of list of string\n",
    "#### TWEET_SCALARS : List of the description of each tweet : Array, shape = (len(nb_tweets), sentence_size * word_size)\n",
    "#### IMPORTANT_WORDS : List of the label of each tweet : Array, shape = (len(nb_tweets), sentence_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Parameters -- #\n",
    "WORD_SIZE = 50  # 50 or 100 or 200 or 300\n",
    "FILL_WITH = 0  # If a word is not in the dictionary, [0, ..., 0] will describe it.\n",
    "SENTIMENT_WEIGHT = 1  # Multiply the sentiment by a factor\n",
    "SENTENCE_SIZE = 50  # What ever\n",
    "OPTIONS = [WORD_SIZE, SENTENCE_SIZE, FILL_WITH, SENTIMENT_WEIGHT]\n",
    "\n",
    "\n",
    "# -- Get the original tweets -- #\n",
    "TWEET_ORIGINALS_TRAIN = TRAIN_SAMPLE[:, 1]\n",
    "TWEET_ORIGINALS_VALID = VALID_SAMPLE[:, 1]\n",
    "print(\"First tweet :\")\n",
    "print(TWEET_ORIGINALS_TRAIN[0])\n",
    "print(\"Shape of TWEET_ORIGINAL :\", TWEET_ORIGINALS_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from descriptors.tweet_string.create_strings import create_strings\n",
    "from descriptors.tokenizer.tokenizer import Tokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "TOKENIZER = Tokenizer()\n",
    "\n",
    "# -- Get the decomposition of the tweets -- #\n",
    "TWEET_STRINGS_TRAIN = create_strings(TWEET_ORIGINALS_TRAIN, TOKENIZER, SENTENCE_SIZE)\n",
    "TWEET_STRINGS_VALID = create_strings(TWEET_ORIGINALS_VALID, TOKENIZER, SENTENCE_SIZE)\n",
    "print(\"Decomposition of the first tweet :\")\n",
    "print(TWEET_STRINGS_TRAIN[0])\n",
    "print(\"Length of TWEET_STRING :\", len(TWEET_STRINGS_TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from descriptors.descriptor_glove.descriptor_glove import tweet_scalar_glove\n",
    "from utils.standardize import standardize\n",
    "\n",
    "\n",
    "# Get the dictionary\n",
    "PATH_DICTIONARY = Path(\"../data/glove_descriptor/glove.6B.{}d.txt\".format(WORD_SIZE))\n",
    "# PATH_DICTIONARY = Path(\"../data/glove_descriptor/sample_test.txt\")\n",
    "DICTIONARY = pd.read_csv(PATH_DICTIONARY, sep=\" \", header=None)\n",
    "\n",
    "# Additional dictionary\n",
    "ADDITIONAL_DIC = {\"..\": \"...\", \"<3\": \"love\"}\n",
    "\n",
    "# Get the sentiments\n",
    "SENTIMENTS_TRAIN = TRAIN_SAMPLE[:, -1]\n",
    "SENTIMENTS_VALID = VALID_SAMPLE[:, -1]\n",
    "\n",
    "# -- Get the decriptions of each tweets -- #\n",
    "TWEET_SCALARS_TRAIN = tweet_scalar_glove(TWEET_STRINGS_TRAIN, SENTIMENTS_TRAIN, DICTIONARY, ADDITIONAL_DIC, OPTIONS)\n",
    "TWEET_SCALARS_VALID = tweet_scalar_glove(TWEET_STRINGS_VALID, SENTIMENTS_VALID, DICTIONARY, ADDITIONAL_DIC, OPTIONS)\n",
    "\n",
    "# Standardize the tweet descriptions\n",
    "standardize(TWEET_SCALARS_TRAIN)\n",
    "standardize(TWEET_SCALARS_VALID)\n",
    "\n",
    "print(\"Description of the first tweet :\")\n",
    "print(TWEET_SCALARS_TRAIN[0])\n",
    "print(\"Shape of TWEET_SCLALAR :\", TWEET_SCALARS_TRAIN.shape)\n",
    "print(TWEET_SCALARS_VALID.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from descriptors.tweet_label.create_labels import create_labels\n",
    "\n",
    "# Create the decompositions of the labels\n",
    "LABEL_ORIGINALS_TRAIN = TRAIN_SAMPLE[:, 2]\n",
    "LABEL_ORIGINALS_VALID = VALID_SAMPLE[:, 2]\n",
    "LABEL_STRINGS_TRAIN = create_strings(LABEL_ORIGINALS_TRAIN, TOKENIZER, SENTENCE_SIZE)\n",
    "LABEL_STRINGS_VALID = create_strings(LABEL_ORIGINALS_VALID, TOKENIZER, SENTENCE_SIZE)\n",
    "\n",
    "# -- Get the labels -- #\n",
    "IMPORTANT_WORDS_TRAIN = create_labels(TWEET_STRINGS_TRAIN, LABEL_STRINGS_TRAIN, SENTENCE_SIZE)\n",
    "\n",
    "IDX = 5\n",
    "print(TWEET_ORIGINALS_TRAIN[IDX])\n",
    "print(LABEL_ORIGINALS_TRAIN[IDX])\n",
    "print(\"Labels :\")\n",
    "print(IMPORTANT_WORDS_TRAIN[IDX])\n",
    "print(\"Shape of IMPORTANT_WORDS :\", IMPORTANT_WORDS_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from utils.post_processing import preds_to_strings\n",
    "from utils.loss import mean_jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All the sentiments in the same Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optimize the number of neighbors and the threshold --- #\n",
    "# Parameter\n",
    "NB_NEIGHBORS_MAX = 400\n",
    "NB_NEIGHBORS_MIN = 20\n",
    "STEP_NEIGH = 40\n",
    "THRESHOLD_MAX = 1\n",
    "THRESHOLD_MIN = 0\n",
    "NB_THRESHOLDS = 15\n",
    "\n",
    "# Variables\n",
    "NB_NEIGHBORS_OPT = 1\n",
    "THRESHOLD_OPT = 1\n",
    "JACCARD_ACC_MAX = 0\n",
    "JACCARD_LIST = []\n",
    "\n",
    "# Modify the sentiments weigth\n",
    "SENTIMENT_WEIGHT = 136\n",
    "SCALARS_TRAIN = TWEET_SCALARS_TRAIN.copy()\n",
    "SCALARS_TRAIN[:, -1] *= SENTIMENT_WEIGHT\n",
    "SCALARS_VALID = TWEET_SCALARS_VALID.copy()\n",
    "SCALARS_VALID[:, -1] *= SENTIMENT_WEIGHT\n",
    "\n",
    "\n",
    "for nb_neigh in range(NB_NEIGHBORS_MIN, NB_NEIGHBORS_MAX, STEP_NEIGH):\n",
    "    # Define the knn\n",
    "    KNN = KNeighborsRegressor(nb_neigh, weights=\"distance\")\n",
    "\n",
    "    # Train the knn\n",
    "    KNN.fit(SCALARS_TRAIN, IMPORTANT_WORDS_TRAIN)\n",
    "\n",
    "    # Scalar predictions\n",
    "    PRED_SCALAR = KNN.predict(SCALARS_VALID)\n",
    "    for threshold in np.linspace(THRESHOLD_MIN, THRESHOLD_MAX, NB_THRESHOLDS):\n",
    "        # Use the threshold\n",
    "        PRED_SCALAR_THRESHOLD = PRED_SCALAR > threshold\n",
    "        \n",
    "        # Get the string predictions\n",
    "        PRED_STRING = preds_to_strings(TWEET_ORIGINALS_VALID, TWEET_STRINGS_VALID, PRED_SCALAR_THRESHOLD)\n",
    "\n",
    "        # Compute the loss\n",
    "        JACCARD_ACC = mean_jaccard(LABEL_ORIGINALS_VALID, PRED_STRING)\n",
    "\n",
    "        # Print results\n",
    "        print(\"Jaccard score\", JACCARD_ACC)\n",
    "        print(\"Threshold\", threshold)\n",
    "        print(\"Number neighbors\", nb_neigh)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Updates\n",
    "        JACCARD_LIST.append(JACCARD_ACC)\n",
    "        if JACCARD_ACC > JACCARD_ACC_MAX:\n",
    "            JACCARD_ACC_MAX = JACCARD_ACC\n",
    "            NB_NEIGHBORS_OPT = nb_neigh    \n",
    "            THRESHOLD_OPT = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib notebook\n",
    "\n",
    "# Plot the results\n",
    "PATH_SAVE = Path(\"../results\")\n",
    "\n",
    "print(\"The optimal number of neighbors to take is :\", NB_NEIGHBORS_OPT)\n",
    "print(\"The optimal threshold is :\", THRESHOLD_OPT)\n",
    "print(\"With this parameters, the Jaccard accuracy is :\", JACCARD_ACC_MAX)\n",
    "\n",
    "# Create the grid and the axes\n",
    "LIST_NEIGHBORS = np.arange(NB_NEIGHBORS_MIN, NB_NEIGHBORS_MAX, STEP_NEIGH)\n",
    "LIST_THRESHOLDS = np.linspace(THRESHOLD_MIN, THRESHOLD_MAX, NB_THRESHOLDS)\n",
    "(NEIGHBORS, THRESHOLDS) = np.meshgrid(LIST_NEIGHBORS, LIST_THRESHOLDS)\n",
    "ax = Axes3D(plt.figure())\n",
    "\n",
    "# Show the plots\n",
    "ax.plot_surface(NEIGHBORS, THRESHOLDS, np.reshape(JACCARD_LIST, (len(LIST_NEIGHBORS), -1)).T)\n",
    "ax.set_xlabel('nb neighbors')\n",
    "ax.set_ylabel('thresholds')\n",
    "ax.set_zlabel('Jaccard Score')\n",
    "plt.savefig(PATH_SAVE / \"glove_knn_train_{}_neighbors_{}_nb_thresholds_{}.jpg\".format(NB_SAMPLES, NB_NEIGHBORS_MAX, NB_THRESHOLDS))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only neutral sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optimize the number of neighbors and the weight sentiment --- #\n",
    "# --- Only neutral sentiments --- #\n",
    "# Parameter\n",
    "NB_NEIGHBORS_MAX_NEUTRAL = 300\n",
    "NB_NEIGHBORS_MIN_NEUTRAL = 5\n",
    "STEP_NEIGH_NEUTRAL = 15\n",
    "THRESHOLD_MAX_NEUTRAL = 1\n",
    "THRESHOLD_MIN_NEUTRAL = 0\n",
    "NB_THRESHOLDS_NEUTRAL = 15\n",
    "\n",
    "# Variables\n",
    "NB_NEIGHBORS_OPT_NEUTRAL = 1\n",
    "THRESHOLD_OPT_NEUTRAL = 1\n",
    "JACCARD_ACC_MAX_NEUTRAL = 0\n",
    "JACCARD_LIST_NEUTRAL = []\n",
    "\n",
    "# Select the neutral sentiments\n",
    "TRAIN_SELECTION_NEUTRAL = np.where(TWEET_SCALARS_TRAIN[:, -1] == 0)\n",
    "VALID_SELECTION_NEUTRAL = np.where(TWEET_SCALARS_VALID[:, -1] == 0)\n",
    "\n",
    "TWEET_SCALARS_TRAIN_NEUTRAL = TWEET_SCALARS_TRAIN[TRAIN_SELECTION_NEUTRAL]\n",
    "IMPORTANT_WORDS_TRAIN_NEUTRAL = IMPORTANT_WORDS_TRAIN[TRAIN_SELECTION_NEUTRAL]\n",
    "\n",
    "TWEET_SCALARS_VALID_NEUTRAL = TWEET_SCALARS_VALID[VALID_SELECTION_NEUTRAL]\n",
    "TWEET_ORIGINALS_VALID_NEUTRAL = TWEET_ORIGINALS_VALID[VALID_SELECTION_NEUTRAL]\n",
    "TWEET_STRINGS_VALID_NEUTRAL = np.array(TWEET_STRINGS_VALID, dtype=object)[VALID_SELECTION_NEUTRAL]\n",
    "LABEL_ORIGINALS_VALID_NEUTRAL = LABEL_ORIGINALS_VALID[VALID_SELECTION_NEUTRAL]\n",
    "\n",
    "\n",
    "for nb_neigh in range(NB_NEIGHBORS_MIN_NEUTRAL, NB_NEIGHBORS_MAX_NEUTRAL, STEP_NEIGH_NEUTRAL):\n",
    "    # Define the knn\n",
    "    KNN = KNeighborsRegressor(nb_neigh, weights=\"distance\")\n",
    "\n",
    "    # Train the knn\n",
    "    KNN.fit(TWEET_SCALARS_TRAIN_NEUTRAL, IMPORTANT_WORDS_TRAIN_NEUTRAL)\n",
    "\n",
    "    # Scalar predictions\n",
    "    PRED_SCALAR_NEUTRAL = KNN.predict(TWEET_SCALARS_VALID_NEUTRAL)\n",
    "    \n",
    "    for threshold in np.linspace(THRESHOLD_MIN, THRESHOLD_MAX, NB_THRESHOLDS):\n",
    "        # Use threshold\n",
    "        PRED_SCALAR_NEUTRAL_THRESHOLD = PRED_SCALAR_NEUTRAL > threshold\n",
    "        \n",
    "        # Get the string predictions\n",
    "        PRED_STRING_NEUTRAL = preds_to_strings(TWEET_ORIGINALS_VALID_NEUTRAL, TWEET_STRINGS_VALID_NEUTRAL, PRED_SCALAR_NEUTRAL_THRESHOLD)\n",
    "\n",
    "        # Compute the loss\n",
    "        JACCARD_ACC_NEUTRAL = mean_jaccard(LABEL_ORIGINALS_VALID_NEUTRAL, PRED_STRING_NEUTRAL)\n",
    "\n",
    "        # Print results\n",
    "        print(\"Jaccard score\", JACCARD_ACC_NEUTRAL)\n",
    "        print(\"Threshold\", threshold)\n",
    "        print(\"Number neighbors\", nb_neigh)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Updates\n",
    "        JACCARD_LIST_NEUTRAL.append(JACCARD_ACC_NEUTRAL)\n",
    "        if JACCARD_ACC_NEUTRAL > JACCARD_ACC_MAX_NEUTRAL:\n",
    "            JACCARD_ACC_MAX_NEUTRAL = JACCARD_ACC_NEUTRAL\n",
    "            NB_NEIGHBORS_OPT_NEUTRAL = nb_neigh\n",
    "            THRESHOLD_OPT_NEUTRAL = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib notebook\n",
    "\n",
    "# Plot the results\n",
    "PATH_SAVE = Path(\"../results\")\n",
    "\n",
    "print(\"The optimal number of neighbors to take is :\", NB_NEIGHBORS_OPT_NEUTRAL)\n",
    "print(\"The optimal threshold is :\", THRESHOLD_OPT_NEUTRAL)\n",
    "print(\"With this parameters, the Jaccard accuracy is :\", JACCARD_ACC_MAX_NEUTRAL)\n",
    "\n",
    "# Create the grid and the axes\n",
    "LIST_NEIGHBORS_NEUTRAL = np.arange(NB_NEIGHBORS_MIN_NEUTRAL, NB_NEIGHBORS_MAX_NEUTRAL, STEP_NEIGH_NEUTRAL)\n",
    "LIST_THRESHOLDS_NEUTRAL = np.linspace(THRESHOLD_MIN_NEUTRAL, THRESHOLD_MAX_NEUTRAL, NB_THRESHOLDS_NEUTRAL)\n",
    "(NEIGHBORS_NEUTRAL, THRESHOLDS_NEUTRAL) = np.meshgrid(LIST_NEIGHBORS_NEUTRAL, LIST_THRESHOLDS_NEUTRAL)\n",
    "ax = Axes3D(plt.figure())\n",
    "\n",
    "# Show the plots\n",
    "ax.plot_surface(NEIGHBORS_NEUTRAL, THRESHOLDS_NEUTRAL, np.reshape(JACCARD_LIST_NEUTRAL, (len(LIST_NEIGHBORS_NEUTRAL), -1)).T)\n",
    "ax.set_xlabel('nb neighbors')\n",
    "ax.set_ylabel('thresholds')\n",
    "ax.set_zlabel('Jaccard Score for neutral sentiments')\n",
    "plt.savefig(PATH_SAVE / \"glove_knn_train_{}_neighbors_{}_nb_thresholds_{}_neutral.jpg\".format(NB_SAMPLES, NB_NEIGHBORS_MAX_NEUTRAL, NB_THRESHOLDS_NEUTRAL))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only positive sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optimize the number of neighbors and the weight sentiment --- #\n",
    "# --- Only positive sentiments --- #\n",
    "# Parameter\n",
    "NB_NEIGHBORS_MAX_POSITIVE = 300\n",
    "NB_NEIGHBORS_MIN_POSITIVE = 5\n",
    "STEP_NEIGH_POSITIVE = 15\n",
    "THRESHOLD_MAX_POSITIVE = 1\n",
    "THRESHOLD_MIN_POSITIVE = 0\n",
    "NB_THRESHOLDS_POSITIVE = 15\n",
    "\n",
    "# Variables\n",
    "NB_NEIGHBORS_OPT_POSITIVE = 1\n",
    "THRESHOLD_OPT_POSITIVE = 1\n",
    "JACCARD_ACC_MAX_POSITIVE = 0\n",
    "JACCARD_LIST_POSITIVE = []\n",
    "\n",
    "# Select the positive sentiments\n",
    "TRAIN_SELECTION_POSITIVE = np.where(TWEET_SCALARS_TRAIN[:, -1] == 1)\n",
    "VALID_SELECTION_POSITIVE = np.where(TWEET_SCALARS_VALID[:, -1] == 1)\n",
    "\n",
    "TWEET_SCALARS_TRAIN_POSITIVE = TWEET_SCALARS_TRAIN[TRAIN_SELECTION_POSITIVE]\n",
    "IMPORTANT_WORDS_TRAIN_POSITIVE = IMPORTANT_WORDS_TRAIN[TRAIN_SELECTION_POSITIVE]\n",
    "\n",
    "TWEET_SCALARS_VALID_POSITIVE = TWEET_SCALARS_VALID[VALID_SELECTION_POSITIVE]\n",
    "TWEET_ORIGINALS_VALID_POSITIVE = TWEET_ORIGINALS_VALID[VALID_SELECTION_POSITIVE]\n",
    "TWEET_STRINGS_VALID_POSITIVE = np.array(TWEET_STRINGS_VALID, dtype=object)[VALID_SELECTION_POSITIVE]\n",
    "LABEL_ORIGINALS_VALID_POSITIVE = LABEL_ORIGINALS_VALID[VALID_SELECTION_POSITIVE]\n",
    "\n",
    "\n",
    "for nb_neigh in range(NB_NEIGHBORS_MIN_POSITIVE, NB_NEIGHBORS_MAX_POSITIVE, STEP_NEIGH_POSITIVE):\n",
    "    # Define the knn\n",
    "    KNN = KNeighborsRegressor(nb_neigh, weights=\"distance\")\n",
    "\n",
    "    # Train the knn\n",
    "    KNN.fit(TWEET_SCALARS_TRAIN_POSITIVE, IMPORTANT_WORDS_TRAIN_POSITIVE)\n",
    "\n",
    "    # Scalar predictions\n",
    "    PRED_SCALAR_POSITIVE = KNN.predict(TWEET_SCALARS_VALID_POSITIVE)\n",
    "    \n",
    "    for threshold in np.linspace(THRESHOLD_MIN, THRESHOLD_MAX, NB_THRESHOLDS):\n",
    "        # Use the treshold\n",
    "        PRED_SCALAR_POSITIVE_THRESHOLD = PRED_SCALAR_POSITIVE > threshold\n",
    "        \n",
    "        # Get the string predictions\n",
    "        PRED_STRING_POSITIVE = preds_to_strings(TWEET_ORIGINALS_VALID_POSITIVE, TWEET_STRINGS_VALID_POSITIVE, PRED_SCALAR_POSITIVE_THRESHOLD)\n",
    "\n",
    "        # Compute the loss\n",
    "        JACCARD_ACC_POSITIVE = mean_jaccard(LABEL_ORIGINALS_VALID_POSITIVE, PRED_STRING_POSITIVE)\n",
    "\n",
    "        # Print results\n",
    "        print(\"Jaccard score\", JACCARD_ACC_POSITIVE)\n",
    "        print(\"Threshold\", threshold)\n",
    "        print(\"Number neighbors\", nb_neigh)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Updates\n",
    "        JACCARD_LIST_POSITIVE.append(JACCARD_ACC_POSITIVE)\n",
    "        if JACCARD_ACC_POSITIVE > JACCARD_ACC_MAX_POSITIVE:\n",
    "            JACCARD_ACC_MAX_POSITIVE = JACCARD_ACC_POSITIVE\n",
    "            NB_NEIGHBORS_OPT_POSITIVE = nb_neigh\n",
    "            THRESHOLD_OPT_POSITIVE = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib notebook\n",
    "\n",
    "# Plot the results\n",
    "PATH_SAVE = Path(\"../results\")\n",
    "\n",
    "print(\"The optimal number of neighbors to take is :\", NB_NEIGHBORS_OPT_POSITIVE)\n",
    "print(\"The optimal threshold is :\", THRESHOLD_OPT_POSITIVE)\n",
    "print(\"With this parameters, the Jaccard accuracy is :\", JACCARD_ACC_MAX_POSITIVE)\n",
    "\n",
    "# Create the grid and the axes\n",
    "LIST_NEIGHBORS_POSITIVE = np.arange(NB_NEIGHBORS_MIN_POSITIVE, NB_NEIGHBORS_MAX_POSITIVE, STEP_NEIGH_POSITIVE)\n",
    "LIST_THRESHOLDS_POSITIVE = np.linspace(THRESHOLD_MIN_POSITIVE, THRESHOLD_MAX_POSITIVE, NB_THRESHOLDS_POSITIVE)\n",
    "(NEIGHBORS_POSITIVE, THRESHOLDS_POSITIVE) = np.meshgrid(LIST_NEIGHBORS_POSITIVE, LIST_THRESHOLDS_POSITIVE)\n",
    "ax = Axes3D(plt.figure())\n",
    "\n",
    "# Show the plots\n",
    "ax.plot_surface(NEIGHBORS_POSITIVE, THRESHOLDS_POSITIVE, np.reshape(JACCARD_LIST_POSITIVE, (len(LIST_NEIGHBORS_POSITIVE), -1)).T)\n",
    "ax.set_xlabel('nb neighbors')\n",
    "ax.set_ylabel('thresholds')\n",
    "ax.set_zlabel('Jaccard Score for positive sentiments')\n",
    "plt.legend()\n",
    "plt.savefig(PATH_SAVE / \"glove_knn_train_{}_neighbors_{}_nb_thresholds_{}_positive.jpg\".format(NB_SAMPLES, NB_NEIGHBORS_MAX_POSITIVE, NB_THRESHOLDS_POSITIVE))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optimize the number of neighbors and the weight sentiment --- #\n",
    "# --- Only negative sentiments --- #\n",
    "# Parameter\n",
    "NB_NEIGHBORS_MAX_NEGATIVE = 300\n",
    "NB_NEIGHBORS_MIN_NEGATIVE = 5\n",
    "STEP_NEIGH_NEGATIVE = 15\n",
    "THRESHOLD_MAX_NEGATIVE = 1\n",
    "THRESHOLD_MIN_NEGATIVE = 0\n",
    "NB_THRESHOLDS_NEGATIVE = 15\n",
    "\n",
    "# Variables\n",
    "NB_NEIGHBORS_OPT_NEGATIVE = 1\n",
    "THRESHOLD_OPT_NEGATIVE = 1\n",
    "JACCARD_ACC_MAX_NEGATIVE = 0\n",
    "JACCARD_LIST_NEGATIVE = []\n",
    "\n",
    "# Select the negative sentiments\n",
    "TRAIN_SELECTION_NEGATIVE = np.where(TWEET_SCALARS_TRAIN[:, -1] == -1)\n",
    "VALID_SELECTION_NEGATIVE = np.where(TWEET_SCALARS_VALID[:, -1] == -1)\n",
    "\n",
    "TWEET_SCALARS_TRAIN_NEGATIVE = TWEET_SCALARS_TRAIN[TRAIN_SELECTION_NEGATIVE]\n",
    "IMPORTANT_WORDS_TRAIN_NEGATIVE = IMPORTANT_WORDS_TRAIN[TRAIN_SELECTION_NEGATIVE]\n",
    "\n",
    "TWEET_SCALARS_VALID_NEGATIVE = TWEET_SCALARS_VALID[VALID_SELECTION_NEGATIVE]\n",
    "TWEET_ORIGINALS_VALID_NEGATIVE = TWEET_ORIGINALS_VALID[VALID_SELECTION_NEGATIVE]\n",
    "TWEET_STRINGS_VALID_NEGATIVE = np.array(TWEET_STRINGS_VALID, dtype=object)[VALID_SELECTION_NEGATIVE]\n",
    "LABEL_ORIGINALS_VALID_NEGATIVE = LABEL_ORIGINALS_VALID[VALID_SELECTION_NEGATIVE]\n",
    "\n",
    "\n",
    "for nb_neigh in range(NB_NEIGHBORS_MIN_NEGATIVE, NB_NEIGHBORS_MAX_NEGATIVE, STEP_NEIGH_NEGATIVE):\n",
    "    # Define the knn\n",
    "    KNN = KNeighborsRegressor(nb_neigh, weights=\"distance\")\n",
    "\n",
    "    # Train the knn\n",
    "    KNN.fit(TWEET_SCALARS_TRAIN_NEGATIVE, IMPORTANT_WORDS_TRAIN_NEGATIVE)\n",
    "\n",
    "    # Scalar predictions\n",
    "    PRED_SCALAR_NEGATIVE = KNN.predict(TWEET_SCALARS_VALID_NEGATIVE)\n",
    "    \n",
    "    for threshold in np.linspace(THRESHOLD_MIN, THRESHOLD_MAX, NB_THRESHOLDS):\n",
    "        # Use threshold\n",
    "        PRED_SCALAR_NEGATIVE_THRESHOLD = PRED_SCALAR_NEGATIVE > threshold\n",
    "\n",
    "        # Get the string predictions\n",
    "        PRED_STRING_NEGATIVE = preds_to_strings(TWEET_ORIGINALS_VALID_NEGATIVE, TWEET_STRINGS_VALID_NEGATIVE, PRED_SCALAR_NEGATIVE_THRESHOLD)\n",
    "\n",
    "        # Compute the loss\n",
    "        JACCARD_ACC_NEGATIVE = mean_jaccard(LABEL_ORIGINALS_VALID_NEGATIVE, PRED_STRING_NEGATIVE)\n",
    "\n",
    "        # Print results\n",
    "        print(\"Jaccard score\", JACCARD_ACC_NEGATIVE)\n",
    "        print(\"Threshold\", threshold)\n",
    "        print(\"Number neighbors\", nb_neigh)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Updates\n",
    "        JACCARD_LIST_NEGATIVE.append(JACCARD_ACC_NEGATIVE)\n",
    "        if JACCARD_ACC_NEGATIVE > JACCARD_ACC_MAX_NEGATIVE:\n",
    "            JACCARD_ACC_MAX_NEGATIVE = JACCARD_ACC_NEGATIVE\n",
    "            NB_NEIGHBORS_OPT_NEGATIVE = nb_neigh\n",
    "            THRESHOLD_OPT_NEGATIVE = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib notebook\n",
    "\n",
    "# Plot the results\n",
    "PATH_SAVE = Path(\"../results\")\n",
    "\n",
    "print(\"The optimal number of neighbors to take is :\", NB_NEIGHBORS_OPT_NEGATIVE)\n",
    "print(\"The optimal threshold is :\", THRESHOLD_OPT_NEGATIVE)\n",
    "print(\"With this parameters, the Jaccard accuracy is :\", JACCARD_ACC_MAX_NEGATIVE)\n",
    "\n",
    "# Create the grid and the axes\n",
    "LIST_NEIGHBORS_NEGATIVE = np.arange(NB_NEIGHBORS_MIN_NEGATIVE, NB_NEIGHBORS_MAX_NEGATIVE, STEP_NEIGH_NEGATIVE)\n",
    "LIST_THRESHOLDS_NEGATIVE = np.linspace(THRESHOLD_MIN_NEGATIVE, THRESHOLD_MAX_NEGATIVE, NB_THRESHOLDS_NEGATIVE)\n",
    "(NEIGHBORS_NEGATIVE, THRESHOLDS_NEGATIVE) = np.meshgrid(LIST_NEIGHBORS_NEGATIVE, LIST_THRESHOLDS_NEGATIVE)\n",
    "ax = Axes3D(plt.figure())\n",
    "\n",
    "# Show the plots\n",
    "ax.plot_surface(NEIGHBORS_NEGATIVE, THRESHOLDS_NEGATIVE, np.reshape(JACCARD_LIST_NEGATIVE, (len(LIST_NEIGHBORS_NEGATIVE), -1)).T)\n",
    "ax.set_xlabel('nb neighbors')\n",
    "ax.set_ylabel('thresholds')\n",
    "ax.set_zlabel('Jaccard Score for negative sentiments')\n",
    "plt.legend()\n",
    "plt.savefig(PATH_SAVE / \"glove_knn_train_{}_neighbors_{}_nb_thresholds_{}_negative.jpg\".format(NB_SAMPLES, NB_NEIGHBORS_MAX_NEGATIVE, NB_THRESHOLDS_NEGATIVE))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive and negative sentiment in the same classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optimize the number of neighbors and the threshold sentiment --- #\n",
    "# --- Positive and negative sentiments --- #\n",
    "# Parameter\n",
    "NB_NEIGHBORS_MAX_POS_NEG = 300\n",
    "NB_NEIGHBORS_MIN_POS_NEG = 5\n",
    "STEP_NEIGH_POS_NEG = 15\n",
    "THRESHOLD_MAX_POS_NEG = 1\n",
    "THRESHOLD_MIN_POS_NEG = 0\n",
    "NB_THRESHOLDS_POS_NEG = 15\n",
    "\n",
    "# Variables\n",
    "NB_NEIGHBORS_OPT_POS_NEG = 1\n",
    "THRESHOLD_OPT_POS_NEG = 1\n",
    "JACCARD_ACC_MAX_POS_NEG = 0\n",
    "JACCARD_LIST_POS_NEG = []\n",
    "\n",
    "# Select the positive and the negative sentiments\n",
    "TRAIN_SELECTION_POS = np.where(TWEET_SCALARS_TRAIN[:, -1] == 1)[0]\n",
    "TRAIN_SELECTION_NEG = np.where(TWEET_SCALARS_TRAIN[:, -1] == -1)[0]\n",
    "TRAIN_SELECTION_POS_NEG = np.concatenate((TRAIN_SELECTION_POS, TRAIN_SELECTION_NEG))\n",
    "                                         \n",
    "VALID_SELECTION_POS = np.where(TWEET_SCALARS_VALID[:, -1] == 1)[0]\n",
    "VALID_SELECTION_NEG = np.where(TWEET_SCALARS_VALID[:, -1] == -1)[0]\n",
    "VALID_SELECTION_POS_NEG = np.concatenate((VALID_SELECTION_POS, VALID_SELECTION_NEG))\n",
    "\n",
    "TWEET_SCALARS_TRAIN_POS_NEG = TWEET_SCALARS_TRAIN[TRAIN_SELECTION_POS_NEG]\n",
    "IMPORTANT_WORDS_TRAIN_POS_NEG = IMPORTANT_WORDS_TRAIN[TRAIN_SELECTION_POS_NEG]\n",
    "\n",
    "TWEET_SCALARS_VALID_POS_NEG = TWEET_SCALARS_VALID[VALID_SELECTION_POS_NEG]\n",
    "TWEET_ORIGINALS_VALID_POS_NEG = TWEET_ORIGINALS_VALID[VALID_SELECTION_POS_NEG]\n",
    "TWEET_STRINGS_VALID_POS_NEG = np.array(TWEET_STRINGS_VALID, dtype=object)[VALID_SELECTION_POS_NEG]\n",
    "LABEL_ORIGINALS_VALID_POS_NEG = LABEL_ORIGINALS_VALID[VALID_SELECTION_POS_NEG]\n",
    "\n",
    "# Modify the sentiments weigth\n",
    "SENTIMENT_WEIGHT = 61\n",
    "TWEET_SCALARS_TRAIN_POS_NEG = TWEET_SCALARS_TRAIN_POS_NEG.copy()\n",
    "TWEET_SCALARS_TRAIN_POS_NEG[:, -1] *= SENTIMENT_WEIGHT\n",
    "TWEET_SCALARS_VALID_POS_NEG = TWEET_SCALARS_VALID_POS_NEG.copy()\n",
    "TWEET_SCALARS_VALID_POS_NEG[:, -1] *= SENTIMENT_WEIGHT\n",
    "\n",
    "\n",
    "for nb_neigh in range(NB_NEIGHBORS_MIN_POS_NEG, NB_NEIGHBORS_MAX_POS_NEG, STEP_NEIGH_POS_NEG):\n",
    "    # Define the knn\n",
    "    KNN = KNeighborsRegressor(nb_neigh, weights=\"distance\")\n",
    "\n",
    "    # Train the knn\n",
    "    KNN.fit(TWEET_SCALARS_TRAIN_POS_NEG, IMPORTANT_WORDS_TRAIN_POS_NEG)\n",
    "\n",
    "    # Scalar predictions\n",
    "    PRED_SCALAR_POS_NEG = KNN.predict(TWEET_SCALARS_VALID_POS_NEG)\n",
    "    \n",
    "    for threshold in np.linspace(THRESHOLD_MIN, THRESHOLD_MAX, NB_THRESHOLDS):\n",
    "        # Use threshold\n",
    "        PRED_SCALAR_POS_NEG_THRESHOLD = PRED_SCALAR_POS_NEG > threshold\n",
    "        \n",
    "        # Get the string predictions\n",
    "        PRED_STRING_POS_NEG = preds_to_strings(TWEET_ORIGINALS_VALID_POS_NEG, TWEET_STRINGS_VALID_POS_NEG, PRED_SCALAR_POS_NEG_THRESHOLD)\n",
    "\n",
    "        # Compute the loss\n",
    "        JACCARD_ACC_POS_NEG = mean_jaccard(LABEL_ORIGINALS_VALID_POS_NEG, PRED_STRING_POS_NEG)\n",
    "\n",
    "        # Print results\n",
    "        print(\"Jaccard score\", JACCARD_ACC_POS_NEG)\n",
    "        print(\"Threshold\", threshold)\n",
    "        print(\"Number neighbors\", nb_neigh)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Updates\n",
    "        JACCARD_LIST_POS_NEG.append(JACCARD_ACC_POS_NEG)\n",
    "        if JACCARD_ACC_POS_NEG > JACCARD_ACC_MAX_POS_NEG:\n",
    "            JACCARD_ACC_MAX_POS_NEG = JACCARD_ACC_POS_NEG\n",
    "            NB_NEIGHBORS_OPT_POS_NEG = nb_neigh\n",
    "            THRESHOLD_OPT_POS_NEG = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib notebook\n",
    "\n",
    "# Plot the results\n",
    "PATH_SAVE = Path(\"../results\")\n",
    "\n",
    "print(\"The optimal number of neighbors to take is :\", NB_NEIGHBORS_OPT_POS_NEG)\n",
    "print(\"The optimal threshold is :\", THRESHOLD_OPT_POS_NEG)\n",
    "print(\"With this parameters, the Jaccard accuracy is :\", JACCARD_ACC_MAX_POS_NEG)\n",
    "\n",
    "# Create the grid and the axes\n",
    "LIST_NEIGHBORS_POS_NEG = np.arange(NB_NEIGHBORS_MIN_POS_NEG, NB_NEIGHBORS_MAX_POS_NEG, STEP_NEIGH_POS_NEG)\n",
    "LIST_THRESHOLDS_POS_NEG = np.linspace(THRESHOLD_MIN_POS_NEG, THRESHOLD_MAX_POS_NEG, NB_THRESHOLDS_POS_NEG)\n",
    "(NEIGHBORS_POS_NEG, THRESHOLDS_POS_NEG) = np.meshgrid(LIST_NEIGHBORS_POS_NEG, LIST_THRESHOLDS_POS_NEG)\n",
    "ax = Axes3D(plt.figure())\n",
    "\n",
    "# Show the plots\n",
    "ax.plot_surface(NEIGHBORS_POS_NEG, THRESHOLDS_POS_NEG, np.reshape(JACCARD_LIST_POS_NEG, (len(LIST_NEIGHBORS_POS_NEG), -1)).T)\n",
    "ax.set_xlabel('nb neighbors')\n",
    "ax.set_ylabel('thresholds')\n",
    "ax.set_zlabel('Jaccard Score for positive and negative sentiments')\n",
    "plt.legend()\n",
    "plt.savefig(PATH_SAVE / \"glove_knn_train_{}_neighbors_{}_nb_thresholds_{}_pos_neg.jpg\".format(NB_SAMPLES, NB_NEIGHBORS_MAX_POS_NEG, NB_THRESHOLDS_POS_NEG))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute borderies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - For Upper bound - # Take the real label with our functions\n",
    "IMPORTANT_WORDS_VALID = create_labels(TWEET_STRINGS_VALID, LABEL_STRINGS_VALID, SENTENCE_SIZE)\n",
    "PRED_STRING_UPPER = preds_to_strings(TWEET_ORIGINALS_VALID, TWEET_STRINGS_VALID, IMPORTANT_WORDS_VALID)\n",
    "\n",
    "# - For Lower bound - # Keep every word\n",
    "EVERY_WORD = np.zeros(IMPORTANT_WORDS_VALID.shape)\n",
    "NB_TWEET_VALID = len(IMPORTANT_WORDS_VALID)\n",
    "for idx_tweet in range(NB_TWEET_VALID):\n",
    "    nb_words_tweet = len(TWEET_STRINGS_VALID[idx_tweet])\n",
    "    EVERY_WORD[idx_tweet, : nb_words_tweet] = 1\n",
    "PRED_STRING_LOWER = preds_to_strings(TWEET_ORIGINALS_VALID, TWEET_STRINGS_VALID, EVERY_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- All the sentiments in the same classifier --- #\n",
    "# - Lower bound - #\n",
    "JACCARD_ACC_LOWER = mean_jaccard(LABEL_ORIGINALS_VALID, PRED_STRING_LOWER)\n",
    "print(\"The trivial solution for the classifier with all the sentiments is\", JACCARD_ACC_LOWER)\n",
    "\n",
    "# - Upper bound - #\n",
    "JACCARD_ACC_UPPER = mean_jaccard(LABEL_ORIGINALS_VALID, PRED_STRING_UPPER)\n",
    "print(\"The upper bound for the classifier with all the sentiments is\", JACCARD_ACC_UPPER)\n",
    "\n",
    "\n",
    "# --- Only neutral sentiments --- #\n",
    "VALID_SELECTION_NEUTRAL = np.where(TWEET_SCALARS_VALID[:, -1] == 0)\n",
    "# - Lower bound - #\n",
    "JACCARD_ACC_LOWER_NEUTRAL = mean_jaccard(LABEL_ORIGINALS_VALID[VALID_SELECTION_NEUTRAL], PRED_STRING_LOWER[VALID_SELECTION_NEUTRAL])\n",
    "print(\"The travial solution for the classifier with only the neutral sentiments is\", JACCARD_ACC_LOWER_NEUTRAL)\n",
    "\n",
    "# - Upper bound - #\n",
    "JACCARD_ACC_UPPER_NEUTRAL = mean_jaccard(LABEL_ORIGINALS_VALID[VALID_SELECTION_NEUTRAL], PRED_STRING_UPPER[VALID_SELECTION_NEUTRAL])\n",
    "print(\"The upper bound for the classifier with only the neutral sentiments is\", JACCARD_ACC_UPPER_NEUTRAL)\n",
    "\n",
    "\n",
    "# --- Only positive sentiments --- #\n",
    "VALID_SELECTION_POSITIVE = np.where(TWEET_SCALARS_VALID[:, -1] == 1)\n",
    "# - Lower bound - #\n",
    "JACCARD_ACC_LOWER_POSITIVE = mean_jaccard(LABEL_ORIGINALS_VALID[VALID_SELECTION_POSITIVE], PRED_STRING_LOWER[VALID_SELECTION_POSITIVE])\n",
    "print(\"The trivial solution for the classifier with only the positive sentiments is\", JACCARD_ACC_LOWER_POSITIVE)\n",
    "\n",
    "# - Upper bound - #\n",
    "JACCARD_ACC_UPPER_POSITIVE = mean_jaccard(LABEL_ORIGINALS_VALID[VALID_SELECTION_POSITIVE], PRED_STRING_UPPER[VALID_SELECTION_POSITIVE])\n",
    "print(\"The upper bound for the classifier with only the positive sentiments is\", JACCARD_ACC_UPPER_POSITIVE)\n",
    "\n",
    "\n",
    "# --- Only negative sentiments --- #\n",
    "VALID_SELECTION_NEGATIVE = np.where(TWEET_SCALARS_VALID[:, -1] == -1)\n",
    "# - Lower bound - #\n",
    "JACCARD_ACC_LOWER_NEGATIVE = mean_jaccard(LABEL_ORIGINALS_VALID[VALID_SELECTION_NEGATIVE], PRED_STRING_LOWER[VALID_SELECTION_NEGATIVE])\n",
    "print(\"The trivial solution for the classifier with only the negative sentiments is\", JACCARD_ACC_LOWER_NEGATIVE)\n",
    "\n",
    "# - Upper bound - #\n",
    "JACCARD_ACC_UPPER_NEGATIVE = mean_jaccard(LABEL_ORIGINALS_VALID[VALID_SELECTION_NEGATIVE], PRED_STRING_UPPER[VALID_SELECTION_NEGATIVE])\n",
    "print(\"The upper bound for the classifier with only the negative sentiments is\", JACCARD_ACC_UPPER_NEGATIVE)\n",
    "\n",
    "\n",
    "# --- Positive and Negative sentiments --- #\n",
    "VALID_SELECTION_POS = np.where(TWEET_SCALARS_VALID[:, -1] == 1)[0]\n",
    "VALID_SELECTION_NEG = np.where(TWEET_SCALARS_VALID[:, -1] == -1)[0]\n",
    "VALID_SELECTION_POS_NEG = np.concatenate((VALID_SELECTION_POS, VALID_SELECTION_NEG))\n",
    "# - Lower bound - #\n",
    "JACCARD_ACC_LOWER_POS_NEG = mean_jaccard(LABEL_ORIGINALS_VALID[VALID_SELECTION_POS_NEG], PRED_STRING_LOWER[VALID_SELECTION_POS_NEG])\n",
    "print(\"The trivial solution for the classifier with the positive and negative sentiments is\", JACCARD_ACC_LOWER_POS_NEG)\n",
    "\n",
    "# - Upper bound - #\n",
    "JACCARD_ACC_UPPER_POS_NEG = mean_jaccard(LABEL_ORIGINALS_VALID[VALID_SELECTION_POS_NEG], PRED_STRING_UPPER[VALID_SELECTION_POS_NEG])\n",
    "print(\"The upper bound for the classifier with the positive and negative sentiments is\", JACCARD_ACC_UPPER_POS_NEG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_SCALAR = KNN.predict(TWEET_SCALARS_VALID)\n",
    "print(\"Nomber of correct match\", np.sum(PREDICTIONS == IMPORTANT_WORDS_VALID))\n",
    "print(\"Number of match to make\", len(PREDICTIONS) * len(PREDICTIONS[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_STRING = preds_to_strings(TWEET_ORIGINALS_VALID, TWEET_STRINGS_VALID, PRED_SCALAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_RESULT = False\n",
    "if SHOW_RESULT:\n",
    "    for idx_tweet in range(len(RESULTS)):\n",
    "        print(TWEET_ORIGINALS_VALID[idx_tweet])\n",
    "        print(IMPORTANT_WORDS_VALID[idx_tweet])\n",
    "        print(PRED_SCALAR[idx_tweet])\n",
    "        print(PRED_STRING[idx_tweet], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loss import mean_jaccard\n",
    "\n",
    "JACCARD_ACC = mean_jaccard(LABEL_ORIGINALS_VALID, PRED_STRING)\n",
    "print(JACCARD_ACC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
