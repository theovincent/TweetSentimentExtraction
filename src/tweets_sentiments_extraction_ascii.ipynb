{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data base import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sample_data\n",
    "\n",
    "NB_SAMPLES = 10\n",
    "PATH_SAMPLE = Path(\"../data/samples/sample_{}.csv\".format(NB_SAMPLES))\n",
    "PATH_CSV = Path(\"../data/train.csv\")\n",
    "\n",
    "SMALL_DATA = sample_data.SampleData(\n",
    "    PATH_CSV, nb_samples=NB_SAMPLES,\n",
    "    save=True, path_save=PATH_SAMPLE\n",
    ")\n",
    "\n",
    "DATAFRAME = pd.read_csv(PATH_SAMPLE)\n",
    "DATA = pd.DataFrame.to_numpy(DATAFRAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       textID                                               text  \\\n",
      "0  e6c9c4b498  Im glad that wasnt my real diver theory test! ...   \n",
      "1  b2423564f7                         AWW thanks hopefully it is   \n",
      "2  983945662b  the columbus blue jackes may be movieing to an...   \n",
      "3  46de360d09  Why do you hurt me? Does it bring you joy to s...   \n",
      "4  d8de266e5b  said final farewells to roommate.  almost fini...   \n",
      "5  1b9c6db26b  : What a let down! No MRI today, neurosurgeon ...   \n",
      "6  8708ae64b8            ugly. What programmes do you have open?   \n",
      "7  0903386a1d   not at my workplace.   but a short-sleeved sh...   \n",
      "8  20021de78f                         thank you for your comment   \n",
      "9  64395a383e  i beat aye to the music hall.  babyy, im like ...   \n",
      "\n",
      "                                       selected_text  sentiment  \n",
      "0  Im glad that wasnt my real diver theory test! ...          0  \n",
      "1                                         AWW thanks          1  \n",
      "2                                         s sad news         -1  \n",
      "3                                               love          1  \n",
      "4  said final farewells to roommate.  almost fini...          0  \n",
      "5                                   What a let down!         -1  \n",
      "6                                              ugly.         -1  \n",
      "7  not at my workplace.   but a short-sleeved shi...          0  \n",
      "8                                              thank          1  \n",
      "9  i beat aye to the music hall.  babyy, im like ...          0  \n"
     ]
    }
   ],
   "source": [
    "print(DATAFRAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4) (10, 50) (10, 50) (10, 1501)\n",
      "\n",
      "Original data :\n",
      "['e6c9c4b498'\n",
      " 'Im glad that wasnt my real diver theory test! I failed  i got 70% 35/50 questions right but i did have 35mins left lol x'\n",
      " 'Im glad that wasnt my real diver theory test! I failed  i got 70% 35/50 questions right but i did have 35mins left lol x'\n",
      " 0]\n",
      "\n",
      "Filled sentence :\n",
      "['Im$$$$$$$$$$$$$$$$$$$$$$$$$$$$' 'glad$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " 'that$$$$$$$$$$$$$$$$$$$$$$$$$$' 'wasnt$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " 'my$$$$$$$$$$$$$$$$$$$$$$$$$$$$' 'real$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " 'diver$$$$$$$$$$$$$$$$$$$$$$$$$' 'theory$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " 'test$$$$$$$$$$$$$$$$$$$$$$$$$$' '!$$$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " 'I$$$$$$$$$$$$$$$$$$$$$$$$$$$$$' 'failed$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " 'i$$$$$$$$$$$$$$$$$$$$$$$$$$$$$' 'got$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " '70$$$$$$$$$$$$$$$$$$$$$$$$$$$$' '%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " '35$$$$$$$$$$$$$$$$$$$$$$$$$$$$' '/$$$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " '50$$$$$$$$$$$$$$$$$$$$$$$$$$$$' 'questions$$$$$$$$$$$$$$$$$$$$$'\n",
      " 'right$$$$$$$$$$$$$$$$$$$$$$$$$' 'but$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " 'i$$$$$$$$$$$$$$$$$$$$$$$$$$$$$' 'did$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " 'have$$$$$$$$$$$$$$$$$$$$$$$$$$' '35mins$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " 'left$$$$$$$$$$$$$$$$$$$$$$$$$$' 'lol$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " 'x$$$$$$$$$$$$$$$$$$$$$$$$$$$$$' '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$' '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$' '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$' '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$' '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$' '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$' '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$' '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$' '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$' '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$'\n",
      " '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$' '$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$']\n",
      "\n",
      "Label :\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "Descriptor :\n",
      "[ 73 109  36 ...  36  36   0]\n"
     ]
    }
   ],
   "source": [
    "from utils.load_data import load_data\n",
    "\n",
    "ALPHANUM_ONLY = False\n",
    "WORD_SIZE = 30\n",
    "SENTENCE_SIZE = 50\n",
    "FILL_WITH = \"$\"\n",
    "SPLIT_PUNCTUATION = True # False if the puncutation \"!?.;,/\" etc are kept stuck to a word\n",
    "\n",
    "X_STRING, X_SCALAR, Y = load_data(\n",
    "    DATA, WORD_SIZE, SENTENCE_SIZE, FILL_WITH, SPLIT_PUNCTUATION, ALPHANUM_ONLY\n",
    ")\n",
    "\n",
    "print(DATA.shape, X_STRING.shape, Y.shape, X_SCALAR.shape)\n",
    "\n",
    "print(\"\\nOriginal data :\")\n",
    "print(DATA[0])\n",
    "print(\"\\nFilled sentence :\")\n",
    "print(X_STRING[0])\n",
    "print(\"\\nLabel :\")\n",
    "print(Y[0])\n",
    "print(\"\\nDescriptor :\")\n",
    "print(X_SCALAR[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ORIGINAL = DATA[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1501)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_SCALAR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                    weights='distance')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_neighbors = 1\n",
    "\n",
    "knn = KNeighborsRegressor(nb_neighbors, weights=\"distance\")\n",
    "knn.fit(X_SCALAR, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = knn.predict(X_SCALAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.post_processing import pred_to_string\n",
    "\n",
    "results = np.zeros(len(predictions), dtype=object)\n",
    "for i in range(len(predictions)):\n",
    "    results[i] = pred_to_string(X_ORIGINAL[i], X_STRING[i], predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im glad that wasnt my real diver theory test! I failed  i got 70% 35/50 questions right but i did have 35mins left lol x\n",
      "Im glad that wasnt my real diver theory test! I failed  i got 70% 35/50 questions right but i did have 35mins left lol x\n",
      "Im glad that wasnt my real diver theory test! I failed i got 70% 35/50 questions right but i did have 35mins left lol x\n",
      "\n",
      " AWW thanks hopefully it is\n",
      "AWW thanks\n",
      "AWW thanks \n",
      "\n",
      "the columbus blue jackes may be movieing to anew city to play at  thats sad news\n",
      "s sad news\n",
      "sad news\n",
      "\n",
      "Why do you hurt me? Does it bring you joy to see me cry? You know I love you more then anything and yet u break my heart everyday!\n",
      "love\n",
      "love \n",
      "\n",
      "said final farewells to roommate.  almost finished packing then it`s dc or bust on the 3rd. california: i divorce you x 3!\n",
      "said final farewells to roommate.  almost finished packing then it`s dc or bust on the 3rd. california: i divorce you x 3!\n",
      "said final farewells to roommate. almost finished packing then it`s dc or bust on the 3rd. california: i divorce you x 3!\n",
      "\n",
      ": What a let down! No MRI today, neurosurgeon didn`t order it--which means we have to come back to OkC soon & we no nothing new\n",
      "What a let down!\n",
      "What a let down! \n",
      "\n",
      " ugly. What programmes do you have open?\n",
      "ugly.\n",
      "ugly. \n",
      "\n",
      " not at my workplace.   but a short-sleeved shirt is absolutely necessary today!\n",
      "not at my workplace.   but a short-sleeved shirt is absolutely necessary today\n",
      "not at my workplace. but a short-sleeved shirt is absolutely necessary today\n",
      "\n",
      " thank you for your comment\n",
      "thank\n",
      "thank \n",
      "\n",
      "i beat aye to the music hall.  babyy, im like the cinnamon that beat the apple to the apple jacks.\n",
      "i beat aye to the music hall.  babyy, im like the cinnamon that beat the apple to the apple jacks.\n",
      "i beat aye to the music hall. babyy, im like the cinnamon that beat the apple to the apple jacks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results)):\n",
    "    print(DATA[i][1])\n",
    "    print(DATA[i][2])\n",
    "    print(results[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on 2\n",
      "0.9666666666666666\n"
     ]
    }
   ],
   "source": [
    "from utils.loss import jaccard\n",
    "\n",
    "avg = 0\n",
    "for i in range(len(results)):\n",
    "    avg += jaccard(results[i], DATA[i, 2])\n",
    "    \n",
    "    if jaccard(results[i], DATA[i, 2]) != 1:\n",
    "        print(\"Error on\", i)\n",
    "avg /= len(results)\n",
    "\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n",
      "\n",
      "Why$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "do$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "you$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "hurt$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "me$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "?$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "Does$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "it$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "bring$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "you$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "joy$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "to$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "see$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "me$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "cry$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "?$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "You$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "know$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "I$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "love$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "you$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "more$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "then$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "anything$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "and$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "yet$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "u$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "break$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "my$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "heart$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "everyday$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "!$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n",
      "\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(DATA[3][2])\n",
    "\n",
    "for i in range(len(X_STRING[3])):\n",
    "    print()\n",
    "    print(X_STRING[3][i])\n",
    "    print(Y[3][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
