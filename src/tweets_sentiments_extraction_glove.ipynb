{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data base import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sample_data\n",
    "\n",
    "nb_samples = 10\n",
    "path_save = Path(\"../data/samples/sample_{}.csv\".format(nb_samples))\n",
    "path_csv = Path(\"../data/train.csv\")\n",
    "\n",
    "SMALL_DATA = sample_data.SampleData(\n",
    "    path_csv, nb_samples=nb_samples,\n",
    "    save=True, path_save=path_save\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SMALL_DATA.sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_descriptor import vectorize_string, convert_labels, descriptor\n",
    "\n",
    "\n",
    "ALPHANUM_ONLY = False\n",
    "WORD_SIZE = 12\n",
    "SENTENCE_SIZE = 20\n",
    "FILL_WITH = \"$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_string_train = np.zeros((nb_samples, SENTENCE_SIZE), dtype=object)\n",
    "X_train = np.zeros((nb_samples, WORD_SIZE * SENTENCE_SIZE))\n",
    "Y_train = np.zeros((nb_samples, SENTENCE_SIZE))\n",
    "\n",
    "for i in range(len(SMALL_DATA.sample_data)):\n",
    "    X_string_train[i] = vectorize_string(\n",
    "        SMALL_DATA.sample_data[\"text\"].to_numpy()[i],\n",
    "        alphanumeric_only=ALPHANUM_ONLY,\n",
    "        sentence_size=SENTENCE_SIZE,\n",
    "        word_size=WORD_SIZE,\n",
    "        fill_with=FILL_WITH\n",
    "    )\n",
    "    X_train[i] = descriptor(X_string_train[i], alphanumeric_only=ALPHANUM_ONLY).reshape(-1)\n",
    "    \n",
    "    Y_train[i] = convert_labels(\n",
    "        X_string_train[i],\n",
    "        vectorize_string(\n",
    "            SMALL_DATA.sample_data[\"selected_text\"].to_numpy()[i],\n",
    "            alphanumeric_only=ALPHANUM_ONLY,\n",
    "            sentence_size=SENTENCE_SIZE,\n",
    "            word_size=WORD_SIZE,\n",
    "            fill_with=FILL_WITH\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_string_train[0])\n",
    "print(X_train[0])\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import  KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_neighbors = 2\n",
    "\n",
    "knn = KNeighborsRegressor(nb_neighbors, weights=\"distance\")\n",
    "knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.post_processing import pred_to_sentence, sentence_to_string, filter_character\n",
    "\n",
    "pred = knn.predict(X_train)\n",
    "meaning_sentences = pred_to_sentence(X_string_train, pred)\n",
    "\n",
    "results = []\n",
    "for sentence in meaning_sentences:\n",
    "    result = \"\"\n",
    "    for word in sentence:\n",
    "        filtered_word = filter_character(word, \"$\")\n",
    "        if len(filtered_word) != 0:\n",
    "            result += filtered_word + \" \"\n",
    "    results.append(result)\n",
    "results=np.array(results, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SMALL_DATA.sample_data[\"selected_text\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loss import jaccard\n",
    "\n",
    "avg = 0\n",
    "for i in range(len(results)):\n",
    "    avg += jaccard(results[i], SMALL_DATA.sample_data[\"selected_text\"].to_numpy()[i])\n",
    "avg /= len(results)\n",
    "\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
